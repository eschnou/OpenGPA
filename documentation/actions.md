# Creating a custom Action

To create a custom action for your Agent, you simply need to:
- Implement the Action interface (from org.opengpa.core)
- Annotate with @Component so it is auto discovered

> [!TIP]
> The community is encouraged to create custom actions and [share them](actions_marketplace.md).
> Don't hesitate to submit a PR with your contributions !

## Implementing the action

### The Action interface

The Action interface is fairly simple:
```java
public interface Action {

    public String getName();
    public String getDescription();
    public List<ActionParameter> getParameters();
    public ActionResult apply(Agent agent, Map<String, String> input);

}
```

- __name__: the name used by the agent to invoke the action. Works better if a meaningful name (e.g. `search_web`).
The convention is tu prefer snake_case for action names.
- __description__: a "mini prompt" explaining what the action is about and any peculiarity in using it. Try to be brief
yet complete enough for the agent to make sense on how to use this action.
- __parameters__: the list of parameters to provide when invoking the action. At this stage only string parameters
are supported. Each parameter has a name and a description. Similary to the action name and descrption, these should
be written *for the agent to understand the action*.

### The apply(..) method and ActionResult

> [!WARNING]
> Applying an action is currently a synchronous call. You therefore need to pay attention to latency
> and have proper timeouts in place. Future work might allow for async action requests.

The `apply` method is called upon request by the agent to invoke the action.
- __input__: the values of the parameters as proved by the agent as a name>value map
- __agent__: a reference to the agent triggering the call, mainly used to fetch the agentId for navigating the
workspace but could be extended to other use cases.

The outcome of applying the action is reflected in a `ActionResult` object:

```java
public class ActionResult {
    private Status status;
    private String output;
    private Object result;
    private String summary;
    private String error;
    private List<Document> documents = new ArrayList<>();
}
```

- __status__: if applying the action was a succes or not
- __error__: in case of failure, a meaningful error *for the agent* to know what happened to it can correct itself.
- __result__: in case of success, the actual result of the action. Can be a complex object. Will be serialized
into JSON when passed back to the agent into the next prompt. You can use Jackson annotations on your result
class to guide this json marshalling. 
- __summary__: a short summary of what happened when invoking the action, this will be shown to the userm as
well as the agent.
- __documents__: if the action resulted in any document written to the workspace

> [!TIP]
> As you can see, the data returned by applying the action should be meaningful both to *the user* as well
> as *the agent*. This will enabe the agent to figure out what happened, reason, and pick the best next action.

## Creating a custom UI to display the action result

OpenGPA server uses Vaadin for its UI layer. This makes it fairly easy to extend the UI by creating an `ActionRenderer`
that will create the required Vaadin components upon rendering an action for a user.

```java

public interface ActionRenderer {
    boolean applies(String action);
    Optional<Component> render(ActionResult result);
}
```

- __applies(String action)__: returns true if the renderer can be applied to the action named `action`.
- __render__(ActionResult result)__: returns a Vaadin Component to be used to render the action. If a result
should be skiped and not rendered, just return `Optional.empty()`.

### Example of rendering an audio player for the TTS action

Here is an example on how the mp3 player used to render TTS action is constructed.


<p align="center">
  <img src="/assets/tts_action.png" width="640" />
</p>

```java

    public Optional<Component> render(ActionResult result) {
        List<Document> documents = result.getDocuments();
        if (documents.isEmpty()) {
            return Optional.empty();
        }

        // Assume the first document is the MP3 generated by TTS
        Document document = documents.getFirst();
        String url = String.format("/api/files/%s/documents/%s", 
                document.getWorkspaceId(), 
                document.getName()
        );

        // Create a DIV as container for the result
        Div resultContainer = new Div();
        resultContainer.setClassName("tts-result-container");
        resultContainer.setWidthFull();
        
        // HTML5 audio tag as a String
        String audioHtml = String.format("<audio controls>"
                + "<source src='%s' type='audio/mp3'>"
                + "Your browser does not support the audio element."
                + "</audio>", url);

        Html audio = new Html(audioHtml);
        resultContainer.add(audio);
        return Optional.of(resultContainer);
    }
```